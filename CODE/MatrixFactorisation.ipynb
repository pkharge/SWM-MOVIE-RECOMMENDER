{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXGlD1RWeWOm",
        "outputId": "fe3aadd5-4542-41ee-b313-3043d465f38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "pip install google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0at3yzYMQCY8",
        "outputId": "e6036b55-2157-44ea-a5f7-5b796b9a5910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOnK8F1dLR6F"
      },
      "outputs": [],
      "source": [
        "#  Install the required packages for the collab code to run\n",
        "!pip install numpy\n",
        "!pip install scikit-surprise\n",
        "import os\n",
        "import pandas as pd\n",
        "from surprise import KNNBasic\n",
        "from surprise import SVD\n",
        "from surprise import SVDpp\n",
        "from surprise import NMF\n",
        "from surprise import accuracy\n",
        "from surprise import AlgoBase\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import KFold\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise.accuracy import rmse\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5M280SQLR6F"
      },
      "outputs": [],
      "source": [
        "# Get the ratings data from ratings.csv file\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/data/ratings.csv')\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xXNM77ULR6G"
      },
      "outputs": [],
      "source": [
        "# Map the relative data into the variable\n",
        "ratings_map_data = {}\n",
        "ratings_map_data['itemID'] = list(ratings_data.movieId)\n",
        "ratings_map_data['userID'] = list(ratings_data.userId)\n",
        "ratings_map_data['rating'] = list(ratings_data.rating)\n",
        "\n",
        "# Contruct a data frame for the ratings data\n",
        "df = pd.DataFrame(ratings_map_data)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2AxjWMMLR6H"
      },
      "outputs": [],
      "source": [
        "# Use 5 fold method\n",
        "from surprise.model_selection import KFold\n",
        "\n",
        "# Set the rating scale\n",
        "rr = Reader(rating_scale=(0.5, 5.0))\n",
        "\n",
        "# Categorize the rating keys\n",
        "rating_map_keys = ['userID', 'itemID', 'rating']\n",
        "filter = df[rating_map_keys]\n",
        "\n",
        "# Get the rating data according the key filters\n",
        "data = Dataset.load_from_df(filter, rr)\n",
        "\n",
        "# Use 5-fold split\n",
        "kf = KFold(n_splits=5)\n",
        "kf.split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REzUl20Djatm"
      },
      "outputs": [],
      "source": [
        "# Utilizing a standard stochastic gradient descent algorithm for predicting ratings within a class\n",
        "class SGDMatixAlgorithmSelf(AlgoBase):\n",
        "    '''An elementary algorithm for predicting ratings grounded on matrix factorization.'''\n",
        "    \n",
        "    def __init__(self, l_r, n_e, n_f):\n",
        "        self.n_f = n_f\n",
        "        self.n_e = n_e\n",
        "        self.l_r = l_r\n",
        "        \n",
        "    # Fit the training dataset\n",
        "    def fit(self, trainset):\n",
        "        first = np.random.normal(0, .1, (trainset.n_users, self.n_f))\n",
        "        second = np.random.normal(0, .1, (trainset.n_items, self.n_f))\n",
        "        \n",
        "        for m in range(self.n_e):\n",
        "            for i, j, k in trainset.all_ratings():\n",
        "                each_val = k - np.dot(first[i], second[j])\n",
        "                first[i] = first[i] + second[j] * each_val * self.l_r\n",
        "                second[j] = second[j] + first[i] * each_val * self.l_r\n",
        "        \n",
        "        self.p = first\n",
        "        self.q = second\n",
        "        self.trainset = trainset\n",
        "\n",
        "    \n",
        "    # Estimate using the train data\n",
        "    def estimate(self, i, j):\n",
        "        if  self.trainset.knows_user(i) and self.trainset.knows_item(j):\n",
        "            return np.dot(self.first[i], self.second[j])\n",
        "        else:\n",
        "            return self.trainset.global_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd5cZoVRLR6J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Remove timestamp from data\n",
        "\n",
        "# Categorize the rating keys\n",
        "rating_map_keys = ['userID', 'itemID', 'rating']\n",
        "filter = df[rating_map_keys]\n",
        "\n",
        "# Set the rating scale\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "\n",
        "# Get the rating data according the key filters\n",
        "data = Dataset.load_from_df(filter, reader)\n",
        "\n",
        "eval = []\n",
        "# Use the matrix factorization algorithm and find evaluation\n",
        "for i in [SGDMatixAlgorithmSelf(.01, 10,10),SVD(), NMF(), KNNBasic()]:\n",
        "    cva = cross_validate(i, data, measures=['RMSE'], cv=4, verbose=False)\n",
        "    tempdataframe = pd.DataFrame.from_dict(cva).mean(axis=0)\n",
        "    algoSplitArray = str(i).split(' ')\n",
        "    finalAlgoSplitArray = algoSplitArray[0].split('.')\n",
        "    tempdataframe.append(pd.Series([finalAlgoSplitArray[-1]],index=['Algorithm']))\n",
        "    eval.append(tempdataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6PJgi_YLR6K"
      },
      "outputs": [],
      "source": [
        "# Print the evaluated data\n",
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO7m3Jq3LR6L"
      },
      "outputs": [],
      "source": [
        "# Split the training and test data in 80:20 ratio\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
        "\n",
        "# Predict the results\n",
        "predictions = algo.fit(trainset).test(testset)\n",
        "\n",
        "# Find the accuracy in RMSE\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6idqGD2xBTVM"
      },
      "outputs": [],
      "source": [
        "# Validate using measures RMSE\n",
        "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuQFLRT9LR6M"
      },
      "outputs": [],
      "source": [
        "def calculate_precision_recall_for_k(predictions, k=10, threshold=3.5):\n",
        "\n",
        "    # Construct user id value to estimate\n",
        "    user_id_to_estimate_map = defaultdict(list)\n",
        "    for user_id, _, ratings_true, estimate_value, _ in predictions:\n",
        "        user_id_to_estimate_map[user_id].append((estimate_value, ratings_true))\n",
        "\n",
        "    # Precision and Recall variables definition\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "\n",
        "    # Return precision and recall for each user id \n",
        "    for user_id, user_ratings in user_id_to_estimate_map.items():\n",
        "\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        n_rel = sum((ratings_true >= threshold) for (_, ratings_true) in user_ratings)\n",
        "\n",
        "        n_rec_k = sum((estimate_value >= threshold) for (estimate_value, _) in user_ratings[:k])\n",
        "\n",
        "        n_rel_and_rec_k = sum(((ratings_true >= threshold) and (estimate_value >= threshold))\n",
        "                              for (estimate_value, ratings_true) in user_ratings[:k])\n",
        "\n",
        "        # Calculate precision and recall\n",
        "        precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_oo0ENtLR6N"
      },
      "outputs": [],
      "source": [
        "# Using K fold technique with 4 splits\n",
        "kf = KFold(n_splits=4)\n",
        "\n",
        "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
        "i = 1\n",
        "\n",
        "# Calculating the final results with split\n",
        "for trainset, testset in kf.split(data):\n",
        "    print(\"Split:\", i)\n",
        "    predictions = algo.fit(trainset).test(testset)\n",
        "\n",
        "    # Calculate the accuracy using RMSE\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "    precisions, recalls = calculate_precision_recall_for_k(predictions, k=5, threshold=4)\n",
        "\n",
        "    print(\"Precision:\", sum(prec for prec in precisions.values()) / len(precisions))\n",
        "    print(\"Recall:\", sum(rec for rec in recalls.values()) / len(recalls))\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWZFtneRLR6P"
      },
      "outputs": [],
      "source": [
        "# Calculate the predictions\n",
        "def getpreds(predictions):\n",
        "    \n",
        "    pred_value = defaultdict(list)    \n",
        "    for user_id, id, ratings_true, estimate_value, _ in predictions:\n",
        "        pred_value[user_id].append((id, estimate_value))\n",
        "\n",
        "    for user_id, user_ratings in pred_value.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return pred_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_9iNHxcLR6P"
      },
      "outputs": [],
      "source": [
        "trainset = data.build_full_trainset()\n",
        "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Get the predictions \n",
        "testset = trainset.build_anti_testset()\n",
        "predictions = algo.test(testset)\n",
        "final_pred = getpreds(predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPIs8RLYLR6P"
      },
      "source": [
        "#### Given that we've obtained all the projected ratings, we'll filter to include solely the top \" \" movies per user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtGv8nBILR6P"
      },
      "outputs": [],
      "source": [
        "#Adjusting the recommendation quantity to 10.\n",
        "n = 10\n",
        "\n",
        "for user_id, user_ratings in final_pred.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "    final_pred[user_id] = user_ratings[:n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mw29KYZLR6P"
      },
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "tmp = pd.DataFrame.from_dict(final_pred)\n",
        "tmp_transpose = tmp.transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vshQIydu03oI"
      },
      "outputs": [],
      "source": [
        "# Compile the result values\n",
        "response = []\n",
        "for user_id,user_ratings in final_pred.items():\n",
        "  response.append(tmp_transpose.loc[user_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "929brbV11KgW"
      },
      "outputs": [],
      "source": [
        "# Setting movie recommenation with respect to movie ids\n",
        "recommendation = []\n",
        "# Compile the recommendation\n",
        "for i in response:\n",
        "  recommended_movie_ids=[]\n",
        "  for x in range(0, n):\n",
        "    recommended_movie_ids.append(i[x][0])\n",
        "  recommendation.append(recommended_movie_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ySjr1Cmd5Zz"
      },
      "outputs": [],
      "source": [
        "recommendation[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfGbme3v1QxZ"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('/content/drive/MyDrive/data/movies.csv')\n",
        "final_value = []\n",
        "\n",
        "# Get final results for the recommendation\n",
        "for i in recommendation:\n",
        "  df = movies[movies['movieId'].isin(i)]\n",
        "  temp = df['title'].tolist()\n",
        "  final_value.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIU_ncsnME7r"
      },
      "outputs": [],
      "source": [
        "# Construct dataframe from the results\n",
        "final_df = pd.DataFrame(final_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uBuXLF6Myrq"
      },
      "outputs": [],
      "source": [
        "# Convert the results to csv file\n",
        "final_df.to_csv('/content/drive/MyDrive/data/file2.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdBzj1SENQ-L"
      },
      "outputs": [],
      "source": [
        "# Set the compiled csv results\n",
        "result = pd.read_csv('/content/drive/MyDrive/data/file2.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gjXqv71vLR6K",
        "6draSSY4LR6N"
      ],
      "name": "MatrixFactorisation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
