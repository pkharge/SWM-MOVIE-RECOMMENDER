{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXGlD1RWeWOm",
        "outputId": "fe3aadd5-4542-41ee-b313-3043d465f38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "pip install google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0at3yzYMQCY8",
        "outputId": "e6036b55-2157-44ea-a5f7-5b796b9a5910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOnK8F1dLR6F"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install scikit-surprise\n",
        "import os\n",
        "import pandas as pd\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import KFold\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise.accuracy import rmse\n",
        "from collections import defaultdict\n",
        "from surprise import KNNBasic\n",
        "from surprise import SVD\n",
        "from surprise import SVDpp\n",
        "from surprise import NMF\n",
        "from surprise import accuracy\n",
        "from surprise import AlgoBase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5M280SQLR6F"
      },
      "outputs": [],
      "source": [
        "# Reading the file ratings and storing it in a dataframe\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/data/ratings.csv')\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xXNM77ULR6G"
      },
      "outputs": [],
      "source": [
        "ratings_map = {}\n",
        "ratings_map['itemID'] = list(ratings.movieId)\n",
        "ratings_map['userID'] = list(ratings.userId)\n",
        "ratings_map['rating'] = list(ratings.rating)\n",
        "\n",
        "df = pd.DataFrame(ratings_map)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2AxjWMMLR6H"
      },
      "outputs": [],
      "source": [
        "# Create 5 folds\n",
        "from surprise.model_selection import KFold\n",
        "rr = Reader(rating_scale=(0.5, 5.0))\n",
        "rating_map_keys = ['userID', 'itemID', 'rating']\n",
        "filter = df[rating_map_keys]\n",
        "data = Dataset.load_from_df(filter, rr)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "kf.split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REzUl20Djatm"
      },
      "outputs": [],
      "source": [
        "# class to predict ratings using a standard stochastic gradient descent algo\n",
        "class SGDMatixSelf(AlgoBase):\n",
        "    '''A basic rating prediction algorithm based on matrix factorization.'''\n",
        "    \n",
        "    def __init__(self, l_r, n_e, n_f):\n",
        "        self.n_f = n_f\n",
        "        self.n_e = n_e\n",
        "        self.lr = l_r\n",
        "        \n",
        "    def fit(self, trainset):\n",
        "        # print('Fit started')\n",
        "        \n",
        "        p = np.random.normal(0, .1, (trainset.n_users, self.n_f))\n",
        "        q = np.random.normal(0, .1, (trainset.n_items, self.n_f))\n",
        "        \n",
        "        for z in range(self.n_e):\n",
        "            for i, j, k in trainset.all_ratings():\n",
        "                e = k - np.dot(p[i], q[j])\n",
        "                p[i] = p[i] + q[j] * e * self.lr\n",
        "                q[j] = q[j] + p[i] * e * self.lr\n",
        "        \n",
        "        self.p = p\n",
        "        self.q = q\n",
        "        self.trainset = trainset\n",
        "\n",
        "    def estimate(self, i, j):\n",
        "        if  self.trainset.knows_user(i) and self.trainset.knows_item(j):\n",
        "            return np.dot(self.p[i], self.q[j])\n",
        "        else:\n",
        "            return self.trainset.global_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd5cZoVRLR6J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#removing timestamp\n",
        "rating_map_keys = ['userID', 'itemID', 'rating']\n",
        "filter = df[rating_map_keys]\n",
        "data = Dataset.load_from_df(filter, reader)\n",
        "\n",
        "eval = []\n",
        "for i in [SGDMatixSelf(.01, 10,10),SVD(), NMF(), KNNBasic()]:\n",
        "    cva = cross_validate(i, data, measures=['RMSE'], cv=4, verbose=False)\n",
        "    tempdataframe = pd.DataFrame.from_dict(cva).mean(axis=0)\n",
        "    algoSplitArray = str(i).split(' ')\n",
        "    finalAlgoSplitArray = algoSplitArray[0].split('.')\n",
        "    tempdataframe.append(pd.Series([finalAlgoSplitArray[-1]],index=['Algorithm']))\n",
        "    eval.append(tempdataframe)\n",
        "\n",
        "                     \n",
        "                                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6PJgi_YLR6K"
      },
      "outputs": [],
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO7m3Jq3LR6L"
      },
      "outputs": [],
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
        "predictions = algo.fit(trainset).test(testset)\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6idqGD2xBTVM"
      },
      "outputs": [],
      "source": [
        "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuQFLRT9LR6M"
      },
      "outputs": [],
      "source": [
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "\n",
        "    userid_to_estimate_map = defaultdict(list)\n",
        "    for user_id, _, ratings_true, estimate_value, _ in predictions:\n",
        "        userid_to_estimate_map[user_id].append((estimate_value, ratings_true))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for user_id, user_ratings in userid_to_estimate_map.items():\n",
        "\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        n_rel = sum((ratings_true >= threshold) for (_, ratings_true) in user_ratings)\n",
        "\n",
        "        n_rec_k = sum((estimate_value >= threshold) for (estimate_value, _) in user_ratings[:k])\n",
        "\n",
        "        n_rel_and_rec_k = sum(((ratings_true >= threshold) and (estimate_value >= threshold))\n",
        "                              for (estimate_value, ratings_true) in user_ratings[:k])\n",
        "\n",
        "        precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_oo0ENtLR6N"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=4)\n",
        "\n",
        "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
        "i = 1\n",
        "for trainset, testset in kf.split(data):\n",
        "    print(\"Split:\", i)\n",
        "    predictions = algo.fit(trainset).test(testset)\n",
        "    accuracy.rmse(predictions, verbose=True)\n",
        "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
        "\n",
        "    print(\"Precision:\", sum(prec for prec in precisions.values()) / len(precisions))\n",
        "    print(\"Recall:\", sum(rec for rec in recalls.values()) / len(recalls))\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWZFtneRLR6P"
      },
      "outputs": [],
      "source": [
        "def getpreds(predictions):\n",
        "    \n",
        "    fin = defaultdict(list)    \n",
        "    for user_id, id, ratings_true, estimate_value, _ in predictions:\n",
        "        fin[user_id].append((id, estimate_value))\n",
        "\n",
        "    for user_id, user_ratings in fin.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return fin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_9iNHxcLR6P"
      },
      "outputs": [],
      "source": [
        "trainset = data.build_full_trainset()\n",
        "algo = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
        "algo.fit(trainset)\n",
        "\n",
        "testset = trainset.build_anti_testset()\n",
        "predictions = algo.test(testset)\n",
        "all_pred = getpreds(predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPIs8RLYLR6P"
      },
      "source": [
        "#### Now as we have all the predicted rating, We'll subset to only top \" \" movies for every user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtGv8nBILR6P"
      },
      "outputs": [],
      "source": [
        "#setting recommendation size to 10\n",
        "n = 10\n",
        "\n",
        "for user_id, user_ratings in all_pred.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "    all_pred[user_id] = user_ratings[:n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1htdMyTK8H8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mw29KYZLR6P"
      },
      "outputs": [],
      "source": [
        "tmp = pd.DataFrame.from_dict(all_pred)\n",
        "tmp_transpose = tmp.transpose()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vshQIydu03oI"
      },
      "outputs": [],
      "source": [
        "res = []\n",
        "for user_id,user_ratings in all_pred.items():\n",
        "  res.append(tmp_transpose.loc[user_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "929brbV11KgW"
      },
      "outputs": [],
      "source": [
        "#movieids of reommended movies\n",
        "recomml = []\n",
        "for i in res:\n",
        "  recommended_movie_ids=[]\n",
        "  for x in range(0, n):\n",
        "    recommended_movie_ids.append(i[x][0])\n",
        "  recomml.append(recommended_movie_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ySjr1Cmd5Zz"
      },
      "outputs": [],
      "source": [
        "recomml[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNrNbwMQd7sr"
      },
      "outputs": [],
      "source": [
        "finall[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfGbme3v1QxZ"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('/content/drive/MyDrive/data/movies.csv')\n",
        "finall = []\n",
        "for i in recomml:\n",
        "  df = movies[movies['movieId'].isin(i)]\n",
        "  temp = df['title'].tolist()\n",
        "  finall.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIU_ncsnME7r"
      },
      "outputs": [],
      "source": [
        "fin = pd.DataFrame(finall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uBuXLF6Myrq"
      },
      "outputs": [],
      "source": [
        "#Saving recommendations to a file\n",
        "fin.to_csv('/content/drive/MyDrive/data/file2.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdBzj1SENQ-L"
      },
      "outputs": [],
      "source": [
        "r = pd.read_csv('/content/drive/MyDrive/data/file2.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gjXqv71vLR6K",
        "6draSSY4LR6N"
      ],
      "name": "MatrixFactorisation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}